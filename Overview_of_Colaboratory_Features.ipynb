{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seyedalicheraghi/Model-Optimization/blob/master/Overview_of_Colaboratory_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "id": "kxNlYFrBVHOQ",
        "outputId": "a511ae1a-d34d-4de5-c8b6-0fb52abe6fee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.7.1)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Super Resolution model definition in PyTorch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "# Some standard imports\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.onnx"
      ],
      "metadata": {
        "id": "mE_fZSp9VMCl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SuperResolutionNet(nn.Module):\n",
        "    def __init__(self, upscale_factor, inplace=False):\n",
        "        super(SuperResolutionNet, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=inplace)\n",
        "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
        "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pixel_shuffle(self.conv4(x))\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv4.weight)"
      ],
      "metadata": {
        "id": "7Uwytg-fVO5f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the super-resolution model by using the above model definition.\n",
        "torch_model = SuperResolutionNet(upscale_factor=3)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    map_location = None\n",
        "torch_model.load_state_dict(model_zoo.load_url('https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'))\n",
        "\n",
        "# Input to the model\n",
        "x = torch.randn(1, 1, 224, 224, requires_grad=True)\n",
        "# torch_out = torch_model(x)\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(torch_model,               # model being run\n",
        "                  x,                         # model input (or a tuple for multiple inputs)\n",
        "                  \"super_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "metadata": {
        "id": "HhUVrb0pUN11",
        "outputId": "07d6fb38-c15d-47ac-805e-08f1b008cdfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth\" to /root/.cache/torch/hub/checkpoints/superres_epoch100-44c6958e.pth\n",
            "100%|██████████| 234k/234k [00:00<00:00, 955kB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VAuBd5QuYQ1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Required Libraries in Google Colab"
      ],
      "metadata": {
        "id": "nLBAsNdvYVtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda # install cuda\n",
        "!pip install tensorrt"
      ],
      "metadata": {
        "id": "mmCe54ZJYcEv",
        "outputId": "899b0358-9086-411c-f594-3f0b3f5cb6c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.2.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2023.1.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (3.9.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.3)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.2.2-cp310-cp310-linux_x86_64.whl size=661405 sha256=d5dbb3a9c804446bfb99bbfc3ea729d687b125b82c4c0c95e2431e9be42009df\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/7b/06/82a395a243fce00035dea9914d92bbef0013401497d849f8bc\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.4 pycuda-2022.2.2 pytools-2023.1.1\n",
            "Collecting tensorrt\n",
            "  Downloading tensorrt-8.6.1.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tensorrt\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-8.6.1-py2.py3-none-any.whl size=16973 sha256=d5b6490f044fbf3082756df670d569e10852cf814b04ad625cfd8bb8cea9ab0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/29/56/abdffd4c604f255b5254bef3f1c598ab7811ea020540599438\n",
            "Successfully built tensorrt\n",
            "Installing collected packages: tensorrt\n",
            "Successfully installed tensorrt-8.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import os\n",
        "import argparse\n",
        "import tensorrt as trt\n",
        "import random\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "import tensorrt as trt\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "v-eQ0bVMYdge"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define Constants"
      ],
      "metadata": {
        "id": "gq9PFU1JYiAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "verbose = False\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE) if verbose else trt.Logger()\n",
        "MAX_BATCH_SIZE = 1\n",
        "model_name = \"ssd-10_backbone\"\n",
        "# model_name = \"yolox_s\"\n",
        "fp16 = False\n",
        "int8 = False\n",
        "dla_core = -1\n",
        "verbose = False\n",
        "engine_path = '%s.trt' % model_name\n",
        "dim  = (1, 3, 1200, 1200)\n",
        "# dim  = (1, 3, 640, 640)"
      ],
      "metadata": {
        "id": "OTbdDb6_Yge-"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load created ONNX model"
      ],
      "metadata": {
        "id": "Qkvc7nG5Yt4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_onnx(model_name):\n",
        "    \"\"\"Read the ONNX file.\"\"\"\n",
        "    onnx_path = '%s.onnx' % model_name\n",
        "    if not os.path.isfile(onnx_path):\n",
        "        print('ERROR: file (%s) not found!  You might want to run yolo_to_onnx.py first to generate it.' % onnx_path)\n",
        "        return None\n",
        "    else:\n",
        "        with open(onnx_path, 'rb') as f:\n",
        "            return f.read()"
      ],
      "metadata": {
        "id": "kf4Zb8eKYqc4"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_data = load_onnx(model_name)"
      ],
      "metadata": {
        "id": "kz01XelDYyyf"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Set network input batch size"
      ],
      "metadata": {
        "id": "vbDtTUXRY3CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_net_batch(network, batch_size):\n",
        "    \"\"\"Set network input batch size.\n",
        "\n",
        "    The ONNX file might have been generated with a different batch size,\n",
        "    say, 64.\n",
        "    \"\"\"\n",
        "    if trt.__version__[0] >= '7':\n",
        "        shape = list(network.get_input(0).shape)\n",
        "        shape[0] = batch_size\n",
        "        network.get_input(0).shape = shape\n",
        "    return network"
      ],
      "metadata": {
        "id": "qOzWAYtyYzVP"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build a TensorRT engine from ONNX\n"
      ],
      "metadata": {
        "id": "PpFkDg8cY_jF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_engine(model_name,do_fp16, do_int8, dla_core, verbose=False):\n",
        "    print('Loading the ONNX file...')\n",
        "    onnx_data = load_onnx(model_name)\n",
        "    if onnx_data is None:\n",
        "        return None\n",
        "\n",
        "    TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE) if verbose else trt.Logger()\n",
        "    EXPLICIT_BATCH = [] if trt.__version__[0] < '7' else \\\n",
        "        [1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)]\n",
        "    with trt.Builder(TRT_LOGGER) as builder, builder.create_network(*EXPLICIT_BATCH) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
        "        if do_int8 and not builder.platform_has_fast_int8:\n",
        "            raise RuntimeError('INT8 not supported on this platform')\n",
        "        if not parser.parse(onnx_data):\n",
        "            print('ERROR: Failed to parse the ONNX file.')\n",
        "            for error in range(parser.num_errors):\n",
        "                print(parser.get_error(error))\n",
        "            return None\n",
        "        network = set_net_batch(network, MAX_BATCH_SIZE)\n",
        "\n",
        "        print('Building the TensorRT engine.  This would take a while...')\n",
        "        print('(Use \"--verbose\" or \"-v\" to enable verbose logging.)')\n",
        "        # new API: build_engine() with builder config\n",
        "        builder.max_batch_size = MAX_BATCH_SIZE\n",
        "        config = builder.create_builder_config()\n",
        "        config.max_workspace_size = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
        "        config.set_flag(trt.BuilderFlag.GPU_FALLBACK)\n",
        "        profile = builder.create_optimization_profile()\n",
        "\n",
        "        profile.set_shape('myin', dim, dim, dim)\n",
        "        config.add_optimization_profile(profile)\n",
        "        engine = builder.build_engine(network, config)\n",
        "        if engine is not None:\n",
        "            print('Completed creating engine.')\n",
        "        return engine"
      ],
      "metadata": {
        "id": "NN7oeu81Y9n3"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "engine = build_engine(model_name, fp16, int8, dla_core, verbose)\n",
        "if engine is None:\n",
        "      raise SystemExit('ERROR: failed to build the TensorRT engine!')\n",
        "with open(engine_path, 'wb') as f:\n",
        "      f.write(engine.serialize())\n",
        "print('Serialized the TensorRT engine to file: %s' % engine_path)"
      ],
      "metadata": {
        "id": "T1tHunJqZK47",
        "outputId": "64ab78c5-7956-48c1-ab05-311528129783",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the ONNX file...\n",
            "Building the TensorRT engine.  This would take a while...\n",
            "(Use \"--verbose\" or \"-v\" to enable verbose logging.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-53522c4c75ad>:23: DeprecationWarning: Use network created with NetworkDefinitionCreationFlag::EXPLICIT_BATCH flag instead.\n",
            "  builder.max_batch_size = MAX_BATCH_SIZE\n",
            "<ipython-input-79-53522c4c75ad>:25: DeprecationWarning: Use set_memory_pool_limit instead.\n",
            "  config.max_workspace_size = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
            "<ipython-input-79-53522c4c75ad>:31: DeprecationWarning: Use build_serialized_network instead.\n",
            "  engine = builder.build_engine(network, config)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed creating engine.\n",
            "Serialized the TensorRT engine to file: yolox_s.trt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from onnx import hub\n",
        "model = hub.load(\"resnet50\")"
      ],
      "metadata": {
        "id": "cw0DWkqwZkyg",
        "outputId": "a60dbcb0-3c23-4f21-e20b-3c59b0132c0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading resnet50 to local path /root/.cache/onnx/hub/vision/classification/resnet/model/af16a04a6ec48ac494065d4439fe9dea590d337b9ca6dc328160ccf04a217b9c_resnet50-v1-7.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /root/.cache/onnx/hub/vision/classification/resnet/model/af16a04a6ec48ac494065d4439fe9dea590d337b9ca6dc328160ccf04a217b9c_resnet50-v1-7.onnx .\n"
      ],
      "metadata": {
        "id": "B6ZvHDeuc6fe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "onnx_path = \"ssd-10\"\n",
        "# Operators to ignore\n",
        "NodesToIgnore = ['Relu_317']\n",
        "NewOutputNodes = ['Add_316']\n",
        "\n",
        "FullGraph_Values = {}\n",
        "\n",
        "Backbone_NewNodes = []\n",
        "Backbone_NewValues = []\n",
        "model = onnx.load(onnx_path + '.onnx')\n",
        "# Separate the backbone from the output head\n",
        "for n in model.graph.initializer:\n",
        "    FullGraph_Values[n.name] = n\n",
        "for n in model.graph.node:\n",
        "    if len(n.output) > 0 and n.output[0] not in NodesToIgnore:\n",
        "        for v in n.input:\n",
        "            if FullGraph_Values.get(v) is not None:\n",
        "                w = FullGraph_Values.get(v)\n",
        "                Backbone_NewValues.append(w)\n",
        "        Backbone_NewNodes.append(n)\n",
        "    else:\n",
        "      break\n",
        "shapes = {}\n",
        "shape_info = onnx.shape_inference.infer_shapes(model)\n",
        "\n",
        "opset_import = shape_info.opset_import\n",
        "# Get shapes of each layer\n",
        "for counter, n in enumerate(shape_info.graph.value_info):\n",
        "    shapes[n.name] = n\n",
        "\n",
        "graph1_input = model.graph.input[0]\n",
        "# graph1_output = model.graph.output\n",
        "# print(graph1_output)\n",
        "graph1_def = onnx.helper.make_graph(\n",
        "    Backbone_NewNodes, 'flex_logix',\n",
        "    [graph1_input],\n",
        "    [shapes.get(NewOutputNodes[0])],\n",
        "    initializer=Backbone_NewValues)\n",
        "shapes.get(NewOutputNodes[0])\n",
        "model = onnx.helper.make_model(graph1_def, producer_name='flex_spatial_conv', opset_imports=opset_import)\n",
        "model.ir_version = 7\n",
        "onnx.save(model, onnx_path + '_backbone.onnx')"
      ],
      "metadata": {
        "id": "ASm4EYE5dV7-"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Z_15SjboCcG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}